## utilitarianism, deontology, and virtue ethics.

### Utilitariasnism:

Most good to most people

> "Actions are right in proportion as they tend to promote happiness, wrong as they tend to produce the reverse of happiness."

- **Act utilitarianism** says that we judge every action by its effect on overall utility.
- **Rule utilitarianism** says that we follow a guideline of general rules that lead to optimal utility for the most amount of people.

### Deontology, also known as duty-based ethics

Universal moral laws

> "Act only on that maxim through which you can at the same time, will that it should become a universal law."

- Intentions are what matters, not the consequences
- You should not use people as a means to an end, but at end in themselves.
  > don't treat people as tools, treat them as people. Respect the people, respect their autonomy, don't tread over them, and make sure that you respect them in a way that you would like to be respected as well.

categorical imperative : if you dont want something to be a universal law, then don't do it.

> One example of a deontology framework would be similar to Asimov's three laws of robotics. It's duty-based, you follow the rules, and that's why it's called duty-based ethics.

### Virtue ethics

Difference for each person : You do what is best in your particular sircumstance.

> Let's say that someone was getting robbed in a back alley, and we have two different people, one is someone who's a little bit of a smaller frame, doesn't exactly know any type of self-defense, what would be the virtuous action for them to do? Would it be for them to run into the back alley and try to beat up the robber, or would it be to call 911 and say, hey, there's someone here being robbed and then they leave the situation? Well, it would depend. For the person that is small, the virtuous action might not be to run in there and fight against the robber. However, for someone who is of a larger frame, someone who is well-versed in the arts of self-defense, that might be the virtuous action because they know what they're doing.

## Ethical framework

a set of guiding principles that governs how an individual or a company behaves and makes decisions.

ethical framework is a set of ethical principles put together in such a way that is operationalized.

### Montreal Declaration

aka the Montreal declaration for the responsible development of artificial intelligence.

The Montreal declaration includes ten fundamental principles :

1. Well-being
   > The development and use of artificial intelligence systems must permit the growth of the well-being of all sentient beings. For our purposes, it's fine to understand all sentient beings as simply human beings.
2. Respect of autonomy
3. The protection of privacy and intimacy
4. Solidarity
   > the development of AI systems must be compatible with maintaining the bonds of human solidarity, among people and generations. In other words, AI should not be trying to replace our intimate human relationships, but they should be tried to foster them instead.
5. Democratic participation
   > transparency, explainability and accountability are all rolled up into this, and that AI systems must meet intelligibility, justifiability, and accessibility criteria's. And must be subject subjected to democratic scrutiny, debate and control.
6. Equity
   > Equity says the people that need more gets more, while the people who need less get less.
7. Diversity and inclusion principle
   > the development of AI systems must be compatible with maintaining social and cultural diversity, and must not restrict the scope of lifestyle choices and personal experience.
8. Prudence principle
   > every person in involved with the development of AI systems, they have to exercise caution by anticipating. As far as possible, the potential adverse consequences of AI system usage, and by taking the necessary precautions to avoid them.
9. Responsibility
   > AI can never be responsible for anything that goes wrong. It always comes down to a human being that makes its decisions.
10. Sustainable development
    > AI systems must be carried out, so as to ensure the strong environmental sustainability of the planet.

### Ethicc guideline for trustworthy AI

One, it should be lawful, respecting all applicable laws and regulations. Two, it should be ethical. It should respect ethical principles and human values. Three, it has to be robust, both from a technological perspective, social environment and its ecological development as well.

### Beijing AI principles

This framework comes in three parts: the first part is for AIRD, research and development; the second part is principals for the use of artificial intelligence; and the third one is principles for the governance of AI.

- AIRD : AI research and development
  > The first one has to be doing good. The second principle is that it has to be for humanity. The third one is that this technology has to be created ethically and responsibly in order for it to be held accountable in case anything goes wrong. The last one is it has to be open and shareable so that any data or any datasets that are created by the artificial intelligence are easily shared amongst the researchers of AI to make sure that it's democratized and easily accessible.
- The use of AI
  > Using AI wisely and properly to make sure that we can mitigate as much misuse as possible. It also talks about informed consent where informed consent means that the end user they know how their data is being processed, they know how the AI is going to be working with them, working for them, or using their datas. Of course, the last one is education and training. Any stakeholders in AI technologies from data programmers, AI programmers, and designers, to end users, they know exactly how the AI works and how to operate these systems.
- The governance of AI
  > for governments to follow, and it talks about optimizing employment. Firstly, AI is going to be used to optimize the employment status instead of replacing people with robots and AI. The second is about harmony and cooperation. Third is the principle of adaptation and moderation. That AI frameworks shouldn't just be static and that governance shouldn't just stay in one place, there should definitely be modifications and adaptations as the technology improves as well.

### Universal guidelines for Artificial Intelligence (UGIA)

Its goal was to promote transparency and accountability for artificial intelligence systems

UGIA has its emphasis on important human rights and its protection of those human rights.

This framework explicitly states that the primary responsibility for AI system must reside with those institutions that fund, develop, and deploy these systems.

### Top 10 principles for ethical artificial intelligence

Identified by UNI Global Union
